{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8156444,"sourceType":"datasetVersion","datasetId":4824900}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# KNN Research","metadata":{}},{"cell_type":"code","source":"import glob\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef load_images(source_dir):\n    input_images = []\n    output_labels = []\n\n    channels = 1\n\n    for image_path in glob.glob(source_dir + \"/**/*.jpg\", recursive=True):\n        image_relative_path = image_path.replace(source_dir, '')\n        relative_path_array = image_relative_path.split(os.path.sep)\n        output_labels.append(relative_path_array[1])\n\n        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        resized = cv2.resize(img, (64, 64))\n        resized = resized.reshape(64, 64, channels)\n        input_images.append(resized/255)\n\n    return input_images, output_labels","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:57:24.099951Z","iopub.execute_input":"2024-07-08T14:57:24.100972Z","iopub.status.idle":"2024-07-08T14:57:24.109385Z","shell.execute_reply.started":"2024-07-08T14:57:24.100936Z","shell.execute_reply":"2024-07-08T14:57:24.108121Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print('Start loading process')\n\nsource_dir = \"/kaggle/input/asl-dataset-research/asl/asl_alphabet_train/asl_alphabet_train\"\ninput_images, output_labels = load_images(source_dir)\n\nprint(\"End loading process\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:57:24.111619Z","iopub.execute_input":"2024-07-08T14:57:24.112013Z","iopub.status.idle":"2024-07-08T15:02:40.700720Z","shell.execute_reply.started":"2024-07-08T14:57:24.111957Z","shell.execute_reply":"2024-07-08T15:02:40.699652Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Start loading process\nEnd loading process\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(output_labels)\n\nlabels_amount = len(label_encoder.classes_)\n\nonehot_encoder = OneHotEncoder(sparse_output=False)\n\ncategorical_column = label_encoder.transform(output_labels)\ninteger_encoded = categorical_column.reshape(len(categorical_column),1)\n\nonehot_encoder.fit(integer_encoded)\noutput_labels_values = onehot_encoder.transform(integer_encoded)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:02:40.702098Z","iopub.execute_input":"2024-07-08T15:02:40.702500Z","iopub.status.idle":"2024-07-08T15:02:40.821723Z","shell.execute_reply.started":"2024-07-08T15:02:40.702462Z","shell.execute_reply":"2024-07-08T15:02:40.820730Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nimages_train, images_test, labels_train, labels_test = train_test_split(input_images, output_labels_values, test_size=0.3, random_state=42)\n\nprint('Training set size : ', len(images_train))\nprint('Testing set size : ', len(images_test))\nprint('Labels set size : ', len(labels_train))\nprint('Labels testing set size : ', len(labels_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:02:40.823868Z","iopub.execute_input":"2024-07-08T15:02:40.824217Z","iopub.status.idle":"2024-07-08T15:02:40.979433Z","shell.execute_reply.started":"2024-07-08T15:02:40.824190Z","shell.execute_reply":"2024-07-08T15:02:40.978420Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Training set size :  60900\nTesting set size :  26100\nLabels set size :  60900\nLabels testing set size :  26100\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimages_train_flat = np.array([image.flatten() for image in images_train])\nimages_test_flat = np.array([image.flatten() for image in images_test])\nlabels_train_flat = np.argmax(np.array(labels_train), axis=1)\nlabels_test_flat = np.argmax(np.array(labels_test), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:02:40.980531Z","iopub.execute_input":"2024-07-08T15:02:40.980833Z","iopub.status.idle":"2024-07-08T15:02:44.306869Z","shell.execute_reply.started":"2024-07-08T15:02:40.980801Z","shell.execute_reply":"2024-07-08T15:02:44.305896Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom sklearn.metrics import classification_report\n\nknn_model = KNeighborsClassifier(n_neighbors = 20)\nknn_fitted_model = knn_model.fit(images_train_flat, labels_train_flat)\nknn_predictions = knn_fitted_model.predict(images_test_flat)\n\nknn_conf_matrix = confusion_matrix(labels_test_flat, knn_predictions)\nknn_accuracy = accuracy_score(labels_test_flat, knn_predictions)\nknn_classification = classification_report(labels_test_flat, knn_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:02:44.308072Z","iopub.execute_input":"2024-07-08T15:02:44.308384Z","iopub.status.idle":"2024-07-08T15:06:06.563299Z","shell.execute_reply.started":"2024-07-08T15:02:44.308351Z","shell.execute_reply":"2024-07-08T15:06:06.562037Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(\"KNN Accuracy : \", knn_accuracy)\nprint()\nprint(knn_classification)\nprint(\"KNN Confusion Matrix : \\n\", knn_conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T15:06:06.565128Z","iopub.execute_input":"2024-07-08T15:06:06.565798Z","iopub.status.idle":"2024-07-08T15:06:06.574577Z","shell.execute_reply.started":"2024-07-08T15:06:06.565754Z","shell.execute_reply":"2024-07-08T15:06:06.573326Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"KNN Accuracy :  0.8780842911877395\n\n              precision    recall  f1-score   support\n\n           0       0.84      0.87      0.85       920\n           1       0.87      0.90      0.88       866\n           2       0.98      0.91      0.95       951\n           3       0.89      0.90      0.90       921\n           4       0.77      0.83      0.80       898\n           5       0.96      0.79      0.87       878\n           6       0.94      0.89      0.92       853\n           7       0.90      0.94      0.92       895\n           8       0.84      0.93      0.88       883\n           9       0.90      0.92      0.91       873\n          10       0.90      0.88      0.89       972\n          11       0.94      0.92      0.93       847\n          12       0.89      0.87      0.88       900\n          13       0.94      0.94      0.94       904\n          14       0.93      0.81      0.86       886\n          15       0.96      0.94      0.95       925\n          16       0.97      0.93      0.95       934\n          17       0.78      0.81      0.79       870\n          18       0.71      0.88      0.79       851\n          19       0.83      0.87      0.85       926\n          20       0.72      0.81      0.76       897\n          21       0.78      0.75      0.77       881\n          22       0.88      0.72      0.79       881\n          23       0.84      0.87      0.85       947\n          24       0.88      0.82      0.85       901\n          25       0.93      0.92      0.92       966\n          26       0.94      0.95      0.94       892\n          27       0.89      1.00      0.94       875\n          28       0.97      0.89      0.93       907\n\n    accuracy                           0.88     26100\n   macro avg       0.88      0.88      0.88     26100\nweighted avg       0.88      0.88      0.88     26100\n\nKNN Confusion Matrix : \n [[800  12   1  11  39   6   0   0   4   0   5   1   6   0   6   0   0   0\n    8   5   0   0   0   3   2   4   0   7   0]\n [  1 780   1   1  25   4   0   0   3   0   7   1   2   0   0   0   0   3\n    0   0   6   2  11   0   0   0   0  19   0]\n [ 10   0 870  43   0   0   0   0   0   0   1   2   0   0   1   0   0   0\n    0   0   0   0   0   0   0  11   0  13   0]\n [ 12  11  12 832   6   5   0   0   5   0   4   2   3   0  18   0   0   0\n    0   1   2   0   0   0   0   1   0   7   0]\n [ 67  34   4   3 742   5   0   0   5   2   2   4   1   1   0   0   0   0\n    2   5   1   1   5   0   0   0   0  13   1]\n [ 27   9   0   8  35 696   9   0  34   3   1   0   4   0   0   0   0   0\n    1   0   1   0   0   0   3   0   0  47   0]\n [  1   0   0   0   8   0 761  48   6  12   2   0   0   0   0   0   0   6\n    0   0   0   0   0   1   7   0   1   0   0]\n [  0   0   0   0   0   0  20 838   0  13   0   0   0   0   0   3   6   1\n    0   0   0   0   0   4   4   0   6   0   0]\n [  3   3   0   1   6   1   0   0 823   7  13   0   2   1   0   0   0   4\n    0   0   5   1   0  12   0   1   0   0   0]\n [  0   0   0   0   2   0   9  12  14 799   0   0  11   3   0   0   0   2\n    4   0   3   0   0   8   0   0   6   0   0]\n [  3  10   0   2   2   0   0   0  43   0 856   1   0   0   0   0   0  26\n    2   0   1  14   6   5   1   0   0   0   0]\n [  0   1   0   0   5   3   0   0   0   0   0 782   2   0  12   0   0   3\n   13  14   0   0   5   2   0   5   0   0   0]\n [  8   4   0   5   6   0   0   0   3   7   1   1 782  32  13   0   0   0\n   31   2   0   1   1   1   0   2   0   0   0]\n [  0   0   0   0   3   0   0   0   0   3   0   0  31 846   1   0   0   0\n    9   1   0   0   1   3   0   6   0   0   0]\n [ 16   0   0  27   7   0   0   0   2   0   0   0  28   5 715   0   0   2\n   40  14   3   8   8   2   0   9   0   0   0]\n [  0   0   0   0   0   0   0  13   1   3   0   0   1   1   1 869  17   2\n    0   5   1   0   0   1   0   0  10   0   0]\n [  0   0   0   0   0   0   0   9   0   0   0   0   0   0   0  31 871   0\n    5   1   1   0   0   1   0   0  15   0   0]\n [  0   0   0   0   2   0   2   0   6   8  18   7   0   0   0   0   0 701\n   16   8  77  16   3   6   0   0   0   0   0]\n [  6   1   0   0  22   0   0   0   1   3   0   1   0   1   1   0   0   4\n  747  25  14   7   1   5   7   5   0   0   0]\n [  1   2   0   1  10   0   0   0   0   0   0  13   3   0   0   0   0   0\n   44 809   2   0   0  18  12  11   0   0   0]\n [  0  12   0   0   6   0   0   0   2   0   2   2   1   0   0   0   0  86\n   11   3 724  23  18   6   0   1   0   0   0]\n [  0   7   0   0  11   0   0   0   0   0   8   4   0   0   0   0   0  15\n   16   2  84 664  20  31  11   0   0   0   8]\n [  1   9   0   0  14   2   0   0   4   0  15   3   0   0   0   0   0  26\n    3   1  59  90 637  10   0   7   0   0   0]\n [  0   1   0   0   4   0   0   0  16   0   5   6   0   1   0   0   0  13\n   43   3  15   6   0 821  12   1   0   0   0]\n [  0   0   0   0   4   0   1   0   6   3  11   4   0   7   1   0   0   6\n   28  50   7   3   7  16 737   2   0   0   8]\n [  0   0   1   2   0   0   0   0   2   0   0   0   2   0   0   0   0   1\n   13  22   2   1   1  20   9 890   0   0   0]\n [  0   0   0   0   1   0   1   2   1  28   1   0   0   0   0   3   3   1\n    0   1   0   0   0   0   0   1 844   0   5]\n [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0\n    0   0   0   0   0   0   0   0   0 873   0]\n [  0   1   0   0   4   1   3  10   0   1   0   0   1   0   0   0   0   2\n    9   2   0  15   0   2  29   3  15   0 809]]\n","output_type":"stream"}]}]}